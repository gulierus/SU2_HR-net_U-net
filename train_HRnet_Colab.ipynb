{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8937dd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "HRNet Training Script - Standalone Version\n",
    "Can be run directly on Colab or locally with GPU\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"HRNet Training Pipeline\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "CONFIG = {\n",
    "    # Training parameters\n",
    "    'TRAIN_SAMPLES': 500,\n",
    "    'VAL_SAMPLES': 100,\n",
    "    'BATCH_SIZE': 8,\n",
    "    'LEARNING_RATE': 1e-3,\n",
    "    'WEIGHT_DECAY': 1e-4,\n",
    "    'DROPOUT_RATE': 0.1,\n",
    "    'EPOCHS': 200,\n",
    "    'PATIENCE': 5,\n",
    "    'SEED': 42,\n",
    "    \n",
    "    # Model parameters\n",
    "    'BASE_CHANNELS': 32,              # 32 or 48\n",
    "    \n",
    "    # Repository settings\n",
    "    'REPO_URL': 'https://github.com/veselm73/SU2.git',\n",
    "    'REPO_DIR': '/content/SU2',\n",
    "    \n",
    "    # Google Drive (for Colab)\n",
    "    'USE_GDRIVE': True,\n",
    "    'SAVE_DIR': '/content/drive/MyDrive/SU2_Project_HRNet',\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75ac3f2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SETUP ENVIRONMENT\n",
    "# ============================================================================\n",
    "\n",
    "def setup_colab():\n",
    "    \"\"\"Setup Google Colab environment.\"\"\"\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        print(\"\\n[1/5] Mounting Google Drive...\")\n",
    "        drive.mount('/content/drive')\n",
    "        os.makedirs(CONFIG['SAVE_DIR'], exist_ok=True)\n",
    "        print(f\" Results will be saved to: {CONFIG['SAVE_DIR']}\")\n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(\"\\n[1/5] Not running on Colab, skipping Drive mount\")\n",
    "        CONFIG['USE_GDRIVE'] = False\n",
    "        CONFIG['SAVE_DIR'] = './results'\n",
    "        os.makedirs(CONFIG['SAVE_DIR'], exist_ok=True)\n",
    "        return False\n",
    "\n",
    "def install_dependencies():\n",
    "    \"\"\"Install required packages.\"\"\"\n",
    "    print(\"\\n[2/5] Installing dependencies...\")\n",
    "    os.system('pip install -q btrack==0.6.5 \"pydantic<2\" pyyaml')\n",
    "    print(\"Dependencies installed\")\n",
    "\n",
    "def clone_repository():\n",
    "    \"\"\"Clone or update repository.\"\"\"\n",
    "    print(\"\\n[3/5] Setting up repository...\")\n",
    "    \n",
    "    if not os.path.exists(CONFIG['REPO_DIR']):\n",
    "        print(f\"Cloning from {CONFIG['REPO_URL']}...\")\n",
    "        os.system(f\"git clone {CONFIG['REPO_URL']} {CONFIG['REPO_DIR']}\")\n",
    "    else:\n",
    "        print(f\"Repository already exists at {CONFIG['REPO_DIR']}\")\n",
    "    \n",
    "    # Add to path\n",
    "    sys.path.append(CONFIG['REPO_DIR'])\n",
    "    os.chdir(CONFIG['REPO_DIR'])\n",
    "    print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "def setup_config():\n",
    "    \"\"\"Create config.yaml file.\"\"\"\n",
    "    print(\"\\n[4/5] Creating configuration...\")\n",
    "    \n",
    "    config_content = f\"\"\"\n",
    "TRAIN_SAMPLES: {CONFIG['TRAIN_SAMPLES']}\n",
    "VAL_SAMPLES: {CONFIG['VAL_SAMPLES']}\n",
    "BATCH_SIZE: {CONFIG['BATCH_SIZE']}\n",
    "LEARNING_RATE: {CONFIG['LEARNING_RATE']}\n",
    "WEIGHT_DECAY: {CONFIG['WEIGHT_DECAY']}\n",
    "DROPOUT_RATE: {CONFIG['DROPOUT_RATE']}\n",
    "EPOCHS: {CONFIG['EPOCHS']}\n",
    "PATIENCE: {CONFIG['PATIENCE']}\n",
    "SEED: {CONFIG['SEED']}\n",
    "\n",
    "MIN_CELLS: 5\n",
    "MAX_CELLS: 15\n",
    "PATCH_SIZE: 128\n",
    "SIM_CONFIG:\n",
    "  na: 1.49\n",
    "  wavelength: 512\n",
    "  px_size: 0.07\n",
    "  wiener_parameter: 0.1\n",
    "  apo_cutoff: 2.0\n",
    "  apo_bend: 0.9\n",
    "\"\"\"\n",
    "    \n",
    "    with open('config.yaml', 'w') as f:\n",
    "        f.write(config_content)\n",
    "    \n",
    "    print(\" Configuration saved to config.yaml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0829aa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "def train_model():\n",
    "    \"\"\"Train HRNet model.\"\"\"\n",
    "    print(\"\\n[5/5] Starting training...\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Import modules\n",
    "    from modules.config import *\n",
    "    from modules.utils import set_seed, plot_training_history\n",
    "    from modules.training_hrnet import train_hrnet_pipeline\n",
    "    \n",
    "    # Set seed\n",
    "    set_seed(CONFIG['SEED'])\n",
    "    \n",
    "    # Train\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Samples: {CONFIG['TRAIN_SAMPLES']} train, {CONFIG['VAL_SAMPLES']} val\")\n",
    "    print(f\"Epochs: {CONFIG['EPOCHS']}, Batch size: {CONFIG['BATCH_SIZE']}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    model, history = train_hrnet_pipeline(\n",
    "        train_samples=CONFIG['TRAIN_SAMPLES'],\n",
    "        val_samples=CONFIG['VAL_SAMPLES'],\n",
    "        epochs=CONFIG['EPOCHS'],\n",
    "        batch_size=CONFIG['BATCH_SIZE'],\n",
    "        learning_rate=CONFIG['LEARNING_RATE'],\n",
    "        weight_decay=CONFIG['WEIGHT_DECAY'],\n",
    "        patience=CONFIG['PATIENCE'],\n",
    "        device=DEVICE,\n",
    "        base_channels=CONFIG['BASE_CHANNELS'],\n",
    "        dropout_rate=CONFIG['DROPOUT_RATE']\n",
    "    )\n",
    "    \n",
    "    # Plot history\n",
    "    print(\"\\nPlotting training history...\")\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def save_model(model):\n",
    "    \"\"\"Save trained model.\"\"\"\n",
    "    print(\"\\nSaving model...\")\n",
    "    \n",
    "    model_name = f\"hrnet\"\n",
    "    \n",
    "    # Save final model\n",
    "    final_path = os.path.join(CONFIG['SAVE_DIR'], f\"{model_name}_final.pth\")\n",
    "    torch.save(model.state_dict(), final_path)\n",
    "    print(f\" Final model saved to: {final_path}\")\n",
    "    \n",
    "    # Save best model if exists\n",
    "    if os.path.exists('best_model.pth'):\n",
    "        import shutil\n",
    "        best_path = os.path.join(CONFIG['SAVE_DIR'], f\"{model_name}_best.pth\")\n",
    "        shutil.copy('best_model.pth', best_path)\n",
    "        print(f\" Best model saved to: {best_path}\")\n",
    "\n",
    "def download_validation_data():\n",
    "    \"\"\"Download validation dataset.\"\"\"\n",
    "    print(\"\\nDownloading validation data...\")\n",
    "    \n",
    "    from modules.utils import download_and_unzip\n",
    "    import requests\n",
    "    \n",
    "    # Download certificate\n",
    "    chain_path = \"/content/chain-harica-cross.pem\"\n",
    "    cert_url = \"https://pki.cesnet.cz/_media/certs/chain-harica-rsa-ov-crosssigned-root.pem\"\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(cert_url, timeout=10, stream=True)\n",
    "        r.raise_for_status()\n",
    "        with open(chain_path, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        print(\" Certificate downloaded\")\n",
    "    except Exception as e:\n",
    "        print(f\" Certificate download failed: {e}\")\n",
    "        chain_path = None\n",
    "    \n",
    "    # Download data\n",
    "    zip_url = \"https://su2.utia.cas.cz/files/labs/final2025/val_and_sota.zip\"\n",
    "    extract_dir = \"/content/val_data\"\n",
    "    \n",
    "    try:\n",
    "        download_and_unzip(zip_url, extract_dir, chain_path)\n",
    "        print(f\" Validation data extracted to: {extract_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"mData download failed: {e}\")\n",
    "\n",
    "def run_tracking(model):\n",
    "    \"\"\"Run tracking parameter sweep.\"\"\"\n",
    "    print(\"\\nRunning tracking parameter sweep...\")\n",
    "    \n",
    "    from modules.sweep import sweep_and_save_gif\n",
    "    \n",
    "    det_param_grid = {\n",
    "        \"threshold\": [0.25, 0.3],\n",
    "        \"min_area\": [4],\n",
    "        \"nms_min_dist\": [3.0]\n",
    "    }\n",
    "    \n",
    "    btrack_param_grid = {\n",
    "        \"do_optimize\": [False],\n",
    "        \"max_search_radius\": [20.0],\n",
    "        \"dist_thresh\": [15.0],\n",
    "        \"time_thresh\": [4, 6],\n",
    "        \"min_track_len\": [10, 15],\n",
    "        \"segmentation_miss_rate\": [0.1],\n",
    "        \"apoptosis_rate\": [0.001],\n",
    "        \"allow_divisions\": [False]\n",
    "    }\n",
    "    \n",
    "    gif_path = os.path.join(\n",
    "        CONFIG['SAVE_DIR'], \n",
    "        f\"hrnet_tracking.gif\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        best_det, best_bt, best_tracks = sweep_and_save_gif(\n",
    "            model,\n",
    "            det_param_grid,\n",
    "            btrack_param_grid,\n",
    "            gif_output=gif_path\n",
    "        )\n",
    "        print(f\"✓ Tracking GIF saved to: {gif_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Tracking failed: {e}\")\n",
    "\n",
    "def print_model_stats(model):\n",
    "    \"\"\"Print model statistics.\"\"\"\n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MODEL STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Base channels: {CONFIG['BASE_CHANNELS']}\")\n",
    "    print(f\"Total parameters: {num_params:,}\")\n",
    "    print(f\"Model size: ~{num_params * 4 / 1024 / 1024:.2f} MB (float32)\")\n",
    "    print(\"=\"*70)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb9f92",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main training pipeline.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STARTING HRNET TRAINING PIPELINE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Setup\n",
    "    is_colab = setup_colab()\n",
    "    install_dependencies()\n",
    "    clone_repository()\n",
    "    setup_config()\n",
    "    \n",
    "    # Train\n",
    "    model, history = train_model()\n",
    "    \n",
    "    # Stats\n",
    "    print_model_stats(model)\n",
    "    \n",
    "    # Save\n",
    "    save_model(model)\n",
    "    \n",
    "    # Optional: Download validation data and run tracking\n",
    "    try:\n",
    "        download_validation_data()\n",
    "        run_tracking(model)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n Optional steps failed: {e}\")\n",
    "        print(\"Model training completed successfully anyway!\")\n",
    "    \n",
    "    # Final message\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\" Models saved to: {CONFIG['SAVE_DIR']}\")\n",
    "    print(f\" Best validation loss: {min(history['val_loss']):.4f}\")\n",
    "    \n",
    "    # Auto-disconnect on Colab\n",
    "    if is_colab:\n",
    "        try:\n",
    "            from google.colab import runtime\n",
    "            print(\"\\nDisconnecting runtime to save compute units...\")\n",
    "            runtime.unassign()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
