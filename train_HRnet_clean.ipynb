{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HRNet Training Pipeline - Clean Version\n",
        "\n",
        "**Comprehensive pipeline for:**\n",
        "- Training HRNet from scratch\n",
        "- Fine-tuning on clustered synthetic data\n",
        "- Parameter sweeps for BTrack and LapTrack\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Configuration\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"HRNet Training Pipeline\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION - These override defaults in modules/config.py\n",
        "# ============================================================================\n",
        "CONFIG = {\n",
        "    # Training parameters\n",
        "    'TRAIN_SAMPLES': 3000,\n",
        "    'VAL_SAMPLES': 400,\n",
        "    'BATCH_SIZE': 16,\n",
        "    'LEARNING_RATE': 2e-3,\n",
        "    'WEIGHT_DECAY': 1e-4,\n",
        "    'DROPOUT_RATE': 0.1,\n",
        "    'EPOCHS': 50,\n",
        "    'PATIENCE': 15,\n",
        "    'SEED': 42,\n",
        "    'BASE_CHANNELS': 48,\n",
        "\n",
        "    # Repository settings\n",
        "    'REPO_URL': 'https://github.com/gulierus/SU2_HR-net',\n",
        "    'REPO_DIR': '/content/SU2_HR-net',\n",
        "\n",
        "    # Google Drive (for Colab)\n",
        "    'USE_GDRIVE': True,\n",
        "    'SAVE_DIR': '/content/drive/MyDrive/SU2_Project_HRNet',\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Setup Environment\n",
        "\n",
        "print(\"\\n[1/5] Setting up environment...\")\n",
        "\n",
        "# Mount Google Drive\n",
        "is_colab = False\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    print(\"  Mounting Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "    os.makedirs(CONFIG['SAVE_DIR'], exist_ok=True)\n",
        "    print(f\"  Results will be saved to: {CONFIG['SAVE_DIR']}\")\n",
        "    is_colab = True\n",
        "except ImportError:\n",
        "    print(\"  Not running on Colab, skipping Drive mount\")\n",
        "    CONFIG['USE_GDRIVE'] = False\n",
        "    CONFIG['SAVE_DIR'] = './results'\n",
        "    os.makedirs(CONFIG['SAVE_DIR'], exist_ok=True)\n",
        "\n",
        "# Install dependencies\n",
        "print(\"\\n[2/5] Installing dependencies...\")\n",
        "!pip install -q btrack==0.6.5 \"pydantic<2\" pyyaml laptrack\n",
        "print(\"  Dependencies installed\")\n",
        "\n",
        "# Clone repository\n",
        "print(\"\\n[3/5] Setting up repository...\")\n",
        "if not os.path.exists(CONFIG['REPO_DIR']):\n",
        "    print(f\"  Cloning from {CONFIG['REPO_URL']}...\")\n",
        "    repo_url = CONFIG['REPO_URL']\n",
        "    if 'github.com' in repo_url:\n",
        "        try:\n",
        "            from google.colab import userdata\n",
        "            github_token = userdata.get('GH_TOKEN')\n",
        "            if github_token:\n",
        "                repo_url = repo_url.replace('https://github.com/', f'https://oauth2:{github_token}@github.com/')\n",
        "                print(\"  Using GitHub token for cloning private repository...\")\n",
        "        except:\n",
        "            pass\n",
        "    !git clone $repo_url $CONFIG['REPO_DIR']\n",
        "else:\n",
        "    print(f\"  Repository already exists at {CONFIG['REPO_DIR']}\")\n",
        "\n",
        "# Add to path\n",
        "sys.path.insert(0, CONFIG['REPO_DIR'])\n",
        "os.chdir(CONFIG['REPO_DIR'])\n",
        "print(f\"  Working directory: {os.getcwd()}\")\n",
        "\n",
        "# Create config.yaml\n",
        "print(\"\\n[4/5] Creating configuration...\")\n",
        "config_content = f\"\"\"\\n",
        "TRAIN_SAMPLES: {CONFIG['TRAIN_SAMPLES']}\n",
        "VAL_SAMPLES: {CONFIG['VAL_SAMPLES']}\n",
        "BATCH_SIZE: {CONFIG['BATCH_SIZE']}\n",
        "LEARNING_RATE: {CONFIG['LEARNING_RATE']}\n",
        "WEIGHT_DECAY: {CONFIG['WEIGHT_DECAY']}\n",
        "DROPOUT_RATE: {CONFIG['DROPOUT_RATE']}\n",
        "EPOCHS: {CONFIG['EPOCHS']}\n",
        "PATIENCE: {CONFIG['PATIENCE']}\n",
        "SEED: {CONFIG['SEED']}\n",
        "\n",
        "MIN_CELLS: 15\n",
        "MAX_CELLS: 49\n",
        "PATCH_SIZE: 128\n",
        "SIM_CONFIG:\n",
        "  na: 1.49\n",
        "  wavelength: 512\n",
        "  px_size: 0.07\n",
        "  wiener_parameter: 0.1\n",
        "  apo_cutoff: 2.0\n",
        "  apo_bend: 0.9\n",
        "\"\"\"\n",
        "with open('config.yaml', 'w') as f:\n",
        "    f.write(config_content)\n",
        "print(\"  Configuration saved to config.yaml\")\n",
        "\n",
        "# Import modules\n",
        "print(\"\\n[5/5] Importing modules...\")\n",
        "from modules.train_HRnet import train_hrnet_pipeline\n",
        "from modules.Fine_tune_HRnet import finetune_hrnet_pipeline\n",
        "from modules.dataset import SyntheticCCPDataset\n",
        "from modules.HRnet_model import HRNet\n",
        "from modules.sweep import sweep_and_save_gif, sweep_laptrack_and_save_gif\n",
        "from modules.utils import save_model_to_drive\n",
        "from modules.config import DEVICE, MIN_CELLS, MAX_CELLS\n",
        "\n",
        "print(f\"  \u2713 All modules imported\")\n",
        "print(f\"  \u2713 Device: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca Visualize Synthetic Dataset\n",
        "\n",
        "Check how the synthetic CCP data looks with clustering enabled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.ndimage import label\n",
        "\n",
        "# Create generator with clusters\n",
        "dataset = SyntheticCCPDataset(\n",
        "    cluster_size_range=(2, 6),\n",
        "    cluster_spread=8.0,\n",
        "    use_clusters=True\n",
        ")\n",
        "\n",
        "print(f\"=== Dataset Settings ===\")\n",
        "print(f\"min_n={dataset.min_n}, max_n={dataset.max_n}\")\n",
        "print(f\"use_clusters={dataset.use_clusters}\")\n",
        "print(f\"cluster_prob={dataset.cluster_prob}\")\n",
        "print()\n",
        "\n",
        "# Generate samples\n",
        "num_samples = 4\n",
        "fig, axes = plt.subplots(2, num_samples, figsize=(15, 7))\n",
        "\n",
        "print(f\"Generating {num_samples} sample images...\")\n",
        "for i in range(num_samples):\n",
        "    img, mask = dataset.data_sample()\n",
        "    \n",
        "    # Count CCPs\n",
        "    labeled, n_cells = label(mask > 0.5)\n",
        "    \n",
        "    # Plot input\n",
        "    axes[0, i].imshow(img, cmap='gray')\n",
        "    axes[0, i].set_title(f'Input ({n_cells} CCPs)')\n",
        "    axes[0, i].axis('off')\n",
        "    \n",
        "    # Plot mask\n",
        "    axes[1, i].imshow(mask, cmap='magma')\n",
        "    axes[1, i].set_title('Ground Truth')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udce5 Download Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "\n",
        "print(\"Downloading validation data...\")\n",
        "\n",
        "# Download certificate\n",
        "chain_path = \"/content/chain-harica-cross.pem\"\n",
        "cert_url = \"https://pki.cesnet.cz/_media/certs/chain-harica-rsa-ov-crosssigned-root.pem\"\n",
        "\n",
        "try:\n",
        "    r = requests.get(cert_url, timeout=10, stream=True)\n",
        "    r.raise_for_status()\n",
        "    with open(chain_path, 'wb') as f:\n",
        "        f.write(r.content)\n",
        "    print(\"\u2713 Certificate downloaded\")\n",
        "except Exception as e:\n",
        "    print(f\"\u26a0 Certificate download failed: {e}\")\n",
        "    chain_path = True\n",
        "\n",
        "# Download validation data\n",
        "zip_url = \"https://su2.utia.cas.cz/files/labs/final2025/val_and_sota.zip\"\n",
        "extract_dir = \"/content/val_data\"\n",
        "zip_path = \"/content/temp_val.zip\"\n",
        "\n",
        "if not os.path.exists(extract_dir):\n",
        "    try:\n",
        "        print(f\"Downloading from: {zip_url}\")\n",
        "        response = requests.get(zip_url, stream=True, verify=chain_path, timeout=60)\n",
        "        response.raise_for_status()\n",
        "        \n",
        "        with open(zip_path, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "        print(\"\u2713 ZIP downloaded\")\n",
        "        \n",
        "        print(\"Extracting...\")\n",
        "        os.makedirs(extract_dir, exist_ok=True)\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_dir)\n",
        "        \n",
        "        os.remove(zip_path)\n",
        "        print(f\"\u2713 Data extracted to: {extract_dir}\")\n",
        "        \n",
        "        print(\"\\nContents:\")\n",
        "        for item in os.listdir(extract_dir):\n",
        "            print(f\"  - {item}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"\u2717 Download failed: {e}\")\n",
        "else:\n",
        "    print(f\"\u2713 Validation data already exists at: {extract_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf Train HRNet from Scratch\n",
        "\n",
        "Train the model on synthetic data without clustering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train HRNet - direct call to repository function\n",
        "model, history = train_hrnet_pipeline(\n",
        "    train_samples=CONFIG['TRAIN_SAMPLES'],\n",
        "    val_samples=CONFIG['VAL_SAMPLES'],\n",
        "    epochs=CONFIG['EPOCHS'],\n",
        "    batch_size=CONFIG['BATCH_SIZE'],\n",
        "    learning_rate=CONFIG['LEARNING_RATE'],\n",
        "    weight_decay=CONFIG['WEIGHT_DECAY'],\n",
        "    patience=CONFIG['PATIENCE'],\n",
        "    device=DEVICE,\n",
        "    base_channels=CONFIG['BASE_CHANNELS'],\n",
        "    dropout_rate=CONFIG['DROPOUT_RATE'],\n",
        "    save_dir=CONFIG['SAVE_DIR'],\n",
        "    save_best=True\n",
        ")\n",
        "\n",
        "# Save model\n",
        "save_model_to_drive(\n",
        "    model,\n",
        "    save_dir=CONFIG['SAVE_DIR'],\n",
        "    model_name=\"hrnet\",\n",
        "    save_best=True\n",
        ")\n",
        "\n",
        "# Print model stats\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"MODEL STATISTICS\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Base channels: {CONFIG['BASE_CHANNELS']}\")\n",
        "print(f\"Total parameters: {num_params:,}\")\n",
        "print(f\"Model size: ~{num_params * 4 / 1024 / 1024:.2f} MB (float32)\")\n",
        "print(f\"{'='*70}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcc8 Training History\n",
        "\n",
        "Visualize training and validation loss over epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Loss curves\n",
        "epochs = range(1, len(history['train_loss']) + 1)\n",
        "axes[0].plot(epochs, history['train_loss'], 'b-', label='Train Loss', marker='o')\n",
        "axes[0].plot(epochs, history['val_loss'], 'r-', label='Val Loss', marker='s')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Training and Validation Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Learning rate\n",
        "axes[1].plot(epochs, history['lr'], 'g-', marker='o')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Learning Rate')\n",
        "axes[1].set_title('Learning Rate Schedule')\n",
        "axes[1].set_yscale('log')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(CONFIG['SAVE_DIR'], 'training_history.png'), dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd2c Evaluate Model on Validation Data\n",
        "\n",
        "Visualize model predictions on real validation data to check detection quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.ndimage import label, center_of_mass, gaussian_filter\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "from modules.utils import open_tiff_file\n",
        "\n",
        "# Load best model\n",
        "model_path = os.path.join(CONFIG['SAVE_DIR'], 'hrnet_best.pth')\n",
        "if not os.path.exists(model_path):\n",
        "    model_path = os.path.join(CONFIG['SAVE_DIR'], 'hrnet_final.pth')\n",
        "\n",
        "eval_model = HRNet(in_channels=1, out_channels=1, base_channels=CONFIG['BASE_CHANNELS'], dropout_rate=CONFIG['DROPOUT_RATE'])\n",
        "eval_model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "eval_model = eval_model.to(DEVICE)\n",
        "eval_model.eval()\n",
        "\n",
        "print(f\"Model loaded from: {model_path}\")\n",
        "\n",
        "# Load validation data\n",
        "video_stack = open_tiff_file('/content/val_data/val.tif').astype(np.float32)\n",
        "gt_df = pd.read_csv('/content/val_data/val.csv')\n",
        "\n",
        "# ROI settings\n",
        "roi_y_min, roi_y_max = 512, 768\n",
        "roi_x_min, roi_x_max = 256, 512\n",
        "\n",
        "# Detection parameters\n",
        "THRESHOLD = 0.5\n",
        "MIN_AREA = 4\n",
        "SIGMA = 1.0\n",
        "\n",
        "def extract_detections(prob_map, threshold=0.5, min_area=4, sigma=1.0):\n",
        "    if sigma > 0:\n",
        "        prob_map = gaussian_filter(prob_map, sigma=sigma)\n",
        "    binary = (prob_map > threshold).astype(np.uint8)\n",
        "    labeled, num = label(binary)\n",
        "    detections = []\n",
        "    for i in range(1, num + 1):\n",
        "        mask = (labeled == i)\n",
        "        if mask.sum() < min_area:\n",
        "            continue\n",
        "        y, x = center_of_mass(mask)\n",
        "        if not np.isnan(x) and not np.isnan(y):\n",
        "            detections.append((x, y))\n",
        "    return np.array(detections)\n",
        "\n",
        "def calculate_deta(gt, pred, thresh=5.0):\n",
        "    if len(gt) == 0 and len(pred) == 0: return 1.0\n",
        "    if len(gt) == 0 or len(pred) == 0: return 0.0\n",
        "    dists = cdist(gt, pred)\n",
        "    sims = np.maximum(0, 1 - dists / thresh)\n",
        "    row, col = linear_sum_assignment(-sims)\n",
        "    tp = sum(sims[r, c] > 0 for r, c in zip(row, col))\n",
        "    return tp / (len(gt) + len(pred) - tp)\n",
        "\n",
        "# Visualize on sample frames\n",
        "frames_to_show = [0, 10, 25, 40, 50]\n",
        "fig, axes = plt.subplots(len(frames_to_show), 3, figsize=(14, 4 * len(frames_to_show)))\n",
        "\n",
        "print(f\"\\nEvaluating on {len(frames_to_show)} sample frames...\")\n",
        "print(f\"Detection params: threshold={THRESHOLD}, min_area={MIN_AREA}, sigma={SIGMA}\\n\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, frame_idx in enumerate(frames_to_show):\n",
        "        # Crop & normalize\n",
        "        crop = video_stack[frame_idx, roi_y_min:roi_y_max, roi_x_min:roi_x_max]\n",
        "        crop_norm = (crop - crop.mean()) / (crop.std() + 1e-8)\n",
        "        \n",
        "        # Inference\n",
        "        tensor = torch.from_numpy(crop_norm).unsqueeze(0).unsqueeze(0).float().to(DEVICE)\n",
        "        prob_map = torch.sigmoid(eval_model(tensor)).cpu().numpy()[0, 0]\n",
        "        \n",
        "        # Extract detections\n",
        "        pred = extract_detections(prob_map, THRESHOLD, MIN_AREA, SIGMA)\n",
        "        \n",
        "        # Ground truth\n",
        "        gt_sub = gt_df[(gt_df['frame'] == frame_idx) &\n",
        "                       gt_df['x'].between(roi_x_min, roi_x_max) &\n",
        "                       gt_df['y'].between(roi_y_min, roi_y_max)]\n",
        "        gt = gt_sub[['x', 'y']].values - [roi_x_min, roi_y_min]\n",
        "        \n",
        "        # Calculate DetA\n",
        "        deta = calculate_deta(gt, pred)\n",
        "        \n",
        "        # Plot input\n",
        "        axes[i, 0].imshow(crop, cmap='gray')\n",
        "        axes[i, 0].set_title(f\"Frame {frame_idx} - Input\")\n",
        "        axes[i, 0].axis('off')\n",
        "        \n",
        "        # Plot probability map\n",
        "        axes[i, 1].imshow(prob_map, cmap='hot', vmin=0, vmax=1)\n",
        "        axes[i, 1].set_title(f\"Probability Map\")\n",
        "        axes[i, 1].axis('off')\n",
        "        \n",
        "        # Plot detections\n",
        "        axes[i, 2].imshow(crop, cmap='gray')\n",
        "        if len(gt) > 0:\n",
        "            axes[i, 2].scatter(gt[:, 0], gt[:, 1], s=120, facecolors='none',\n",
        "                               edgecolors='lime', linewidth=2, label=f'GT ({len(gt)})')\n",
        "        if len(pred) > 0:\n",
        "            axes[i, 2].scatter(pred[:, 0], pred[:, 1], c='red', marker='x',\n",
        "                               s=60, linewidth=2, label=f'Pred ({len(pred)})')\n",
        "        axes[i, 2].legend(loc='upper right')\n",
        "        axes[i, 2].set_title(f\"Detections (DetA={deta:.3f})\")\n",
        "        axes[i, 2].axis('off')\n",
        "        \n",
        "        print(f\"Frame {frame_idx}: GT={len(gt)}, Pred={len(pred)}, DetA={deta:.3f}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(CONFIG['SAVE_DIR'], 'detection_evaluation.png'), dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n\u2713 Evaluation visualization saved\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd27 Fine-tune HRNet on Clustered Data\n",
        "\n",
        "Fine-tune the pretrained model on more realistic clustered synthetic data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fine-tuning configuration\n",
        "FINETUNE_CONFIG = {\n",
        "    'train_samples': 2000,\n",
        "    'val_samples': 300,\n",
        "    'epochs': 25,\n",
        "    'learning_rate': 2e-4,  # Lower LR for fine-tuning\n",
        "    'cluster_prob': 0.6,\n",
        "    'cluster_size_range': (1, 8),\n",
        "    'cluster_spread': 7.0\n",
        "}\n",
        "\n",
        "print(\"Fine-tuning configuration:\")\n",
        "for key, value in FINETUNE_CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "print()\n",
        "\n",
        "# Path to pretrained model\n",
        "pretrained_path = os.path.join(CONFIG['SAVE_DIR'], 'hrnet_best.pth')\n",
        "if not os.path.exists(pretrained_path):\n",
        "    pretrained_path = os.path.join(CONFIG['SAVE_DIR'], 'hrnet_final.pth')\n",
        "\n",
        "print(f\"Loading pretrained model from: {pretrained_path}\\n\")\n",
        "\n",
        "# Fine-tune\n",
        "model_finetuned, history_ft = finetune_hrnet_pipeline(\n",
        "    pretrained_path=pretrained_path,\n",
        "    train_samples=FINETUNE_CONFIG['train_samples'],\n",
        "    val_samples=FINETUNE_CONFIG['val_samples'],\n",
        "    epochs=FINETUNE_CONFIG['epochs'],\n",
        "    batch_size=CONFIG['BATCH_SIZE'],\n",
        "    learning_rate=FINETUNE_CONFIG['learning_rate'],\n",
        "    weight_decay=CONFIG['WEIGHT_DECAY'],\n",
        "    patience=CONFIG['PATIENCE'],\n",
        "    device=DEVICE,\n",
        "    base_channels=CONFIG['BASE_CHANNELS'],\n",
        "    dropout_rate=CONFIG['DROPOUT_RATE'],\n",
        "    save_dir=CONFIG['SAVE_DIR'],\n",
        "    use_clusters=True,\n",
        "    cluster_prob=FINETUNE_CONFIG['cluster_prob'],\n",
        "    cluster_size_range=FINETUNE_CONFIG['cluster_size_range'],\n",
        "    cluster_spread=FINETUNE_CONFIG['cluster_spread']\n",
        ")\n",
        "\n",
        "print(f\"\\n\u2713 Fine-tuned model saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Loss curves\n",
        "epochs_ft = range(1, len(history_ft['train_loss']) + 1)\n",
        "axes[0].plot(epochs_ft, history_ft['train_loss'], 'b-', label='Train Loss', marker='o')\n",
        "axes[0].plot(epochs_ft, history_ft['val_loss'], 'r-', label='Val Loss', marker='s')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Fine-tuning: Training and Validation Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Learning rate\n",
        "axes[1].plot(epochs_ft, history_ft['lr'], 'g-', marker='o')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Learning Rate')\n",
        "axes[1].set_title('Fine-tuning: Learning Rate Schedule')\n",
        "axes[1].set_yscale('log')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(CONFIG['SAVE_DIR'], 'finetuning_history.png'), dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd0d BTrack Parameter Sweep\n",
        "\n",
        "Find optimal detection and tracking parameters using BTrack algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define parameter grids for sweep\n",
        "det_param_grid = {\n",
        "    \"threshold\": [0.2, 0.25, 0.3],\n",
        "    \"min_area\": [3, 4],\n",
        "    \"nms_min_dist\": [3]\n",
        "}\n",
        "\n",
        "btrack_param_grid = {\n",
        "    \"do_optimize\": [False],\n",
        "    \"max_search_radius\": [15.0, 20.0, 25.0, 30.0],\n",
        "    \"dist_thresh\": [12.0, 15.0, 18.0, 20.0],\n",
        "    \"time_thresh\": [3, 4, 5, 6],\n",
        "    \"min_track_len\": [8, 10, 12],\n",
        "    \"segmentation_miss_rate\": [0.05, 0.1, 0.15],\n",
        "    \"apoptosis_rate\": [0.001],\n",
        "    \"allow_divisions\": [False],\n",
        "    \"gap_closing_max_frame_count\": [2, 3, 4]\n",
        "}\n",
        "\n",
        "gif_path_btrack = os.path.join(CONFIG['SAVE_DIR'], \"hrnet_tracking_btrack.gif\")\n",
        "\n",
        "print(\"Starting BTrack parameter sweep...\")\n",
        "print(f\"Total combinations to test: {len(det_param_grid['threshold']) * len(det_param_grid['min_area'])}\")\n",
        "print(f\"  \u00d7 {len(btrack_param_grid['max_search_radius']) * len(btrack_param_grid['dist_thresh']) * len(btrack_param_grid['time_thresh'])}\")\n",
        "print(f\"  \u00d7 {len(btrack_param_grid['min_track_len']) * len(btrack_param_grid['segmentation_miss_rate']) * len(btrack_param_grid['gap_closing_max_frame_count'])}\")\n",
        "print()\n",
        "\n",
        "# Run sweep\n",
        "best_det_bt, best_bt, best_tracks_bt = sweep_and_save_gif(\n",
        "    model_finetuned,\n",
        "    det_param_grid,\n",
        "    btrack_param_grid,\n",
        "    gif_output=gif_path_btrack\n",
        ")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"BTRACK BEST RESULTS\")\n",
        "print(f\"{'='*70}\")\n",
        "print(\"Best detection params:\")\n",
        "for k, v in best_det_bt.__dict__.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "print(\"\\nBest BTrack params:\")\n",
        "for k, v in best_bt.__dict__.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "print(f\"\\n\u2713 Results saved to: {gif_path_btrack}\")\n",
        "print(f\"{'='*70}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Display the generated GIF\n",
        "if os.path.exists(gif_path_btrack):\n",
        "    print(\"BTrack tracking visualization:\")\n",
        "    display(Image(filename=gif_path_btrack))\n",
        "else:\n",
        "    print(f\"GIF not found at: {gif_path_btrack}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd0d LapTrack Parameter Sweep\n",
        "\n",
        "Find optimal parameters using LapTrack (graph-based optimization)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define parameter grids for LapTrack\n",
        "det_param_grid_lap = {\n",
        "    \"threshold\": [0.5, 0.55, 0.6],\n",
        "    \"min_area\": [4],\n",
        "    \"nms_min_dist\": [3]\n",
        "}\n",
        "\n",
        "laptrack_param_grid = {\n",
        "    \"max_distance\": [6.0, 8.0, 9.0],\n",
        "    \"track_cost_cutoff\": [10.0],\n",
        "    \"gap_closing_max_frame_count\": [2, 3, 4],\n",
        "    \"gap_closing_cost_cutoff\": [15.0],\n",
        "    \"min_track_len\": [5, 8, 10]\n",
        "}\n",
        "\n",
        "gif_path_lap = os.path.join(CONFIG['SAVE_DIR'], \"hrnet_tracking_laptrack.gif\")\n",
        "\n",
        "print(\"Starting LapTrack parameter sweep...\")\n",
        "print(f\"Detection combinations: {len(det_param_grid_lap['threshold'])}\")\n",
        "print(f\"LapTrack combinations: {len(laptrack_param_grid['max_distance']) * len(laptrack_param_grid['gap_closing_max_frame_count']) * len(laptrack_param_grid['min_track_len'])}\")\n",
        "print()\n",
        "\n",
        "# Run sweep\n",
        "best_det_lap, best_lap, best_tracks_lap, all_results = sweep_laptrack_and_save_gif(\n",
        "    model_finetuned,\n",
        "    det_param_grid_lap,\n",
        "    laptrack_param_grid,\n",
        "    gif_output=gif_path_lap\n",
        ")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"LAPTRACK BEST RESULTS\")\n",
        "print(f\"{'='*70}\")\n",
        "print(\"Best detection params:\")\n",
        "for k, v in best_det_lap.__dict__.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "print(\"\\nBest LapTrack params:\")\n",
        "for k, v in best_lap.__dict__.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "print(f\"\\n\u2713 Results saved to: {gif_path_lap}\")\n",
        "print(f\"{'='*70}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the generated GIF\n",
        "if os.path.exists(gif_path_lap):\n",
        "    print(\"LapTrack tracking visualization:\")\n",
        "    display(Image(filename=gif_path_lap))\n",
        "else:\n",
        "    print(f\"GIF not found at: {gif_path_lap}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u2705 Pipeline Complete!\n",
        "\n",
        "All training and evaluation steps completed. Check your Google Drive for saved models and results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nAll results saved to: {CONFIG['SAVE_DIR']}\")\n",
        "print(\"\\nGenerated files:\")\n",
        "print(\"  Models:\")\n",
        "print(\"    - hrnet_final.pth (initial training)\")\n",
        "print(\"    - hrnet_best.pth (best checkpoint)\")\n",
        "print(\"    - hrnet_finetuned_final.pth (fine-tuned)\")\n",
        "print(\"    - hrnet_finetuned_best.pth (fine-tuned best)\")\n",
        "print(\"\\n  Visualizations:\")\n",
        "print(\"    - synthetic_data_samples.png\")\n",
        "print(\"    - training_history.png\")\n",
        "print(\"    - detection_evaluation.png\")\n",
        "print(\"    - finetuning_history.png\")\n",
        "print(\"\\n  Tracking Results:\")\n",
        "print(\"    - hrnet_tracking_btrack.gif\")\n",
        "print(\"    - hrnet_tracking_laptrack.gif\")\n",
        "print(\"    - best_hota_btrack.txt\")\n",
        "print(\"    - best_hota_laptrack.txt\")\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}